##### Spark和MapReduce(MR)的区别

```tex
首先Spark是借鉴了mapreduce并在其基础上发展起来的，继承了其分布式计算的优点并改进了mapreduce明显的缺陷，但是二者也有不少的差异具体如下：

1: MR是基于进程，spark是基于线程
2: Spark的多个task跑在同一个进程上，这个进程会伴随spark应用程序的整个生命周期，即使没有作业进行，进程也是存在的
3: MR的每一个task都是一个进程，当task完成时，进程也会结束
    所以，spark比MR快的原因也在这，MR启动就需要申请资源，用完就销毁，但是spark把进程拿到以后，这个进程会一直存在，即使没有job在跑，所以后边的job可以直接启动，不需要再重新申请资源

```

##### 1、速度

```tex
spark把运算的中间数据存放在内存，迭代计算效率更高；mapreduce的中间结果需要落地，需要保存到磁盘，这样必然会有磁盘io操做，影响性能。
```

##### 2、容错性

```tex
spark容错性高，它通过弹性分布式数据集RDD来实现高效容错，RDD是一组分布式的存储在节点内存中的只读性质的数据集，这些集合是弹性的，某一部分丢失或者出错，可以通过整个数据集的计算流程的血缘关系来实现重建；mapreduce的话容错可能只能重新计算了，成本较高。
```

##### 3、适用面

```text
spark更加通用，spark提供了transformation和action这两大类的多个功能api，另外还有流式处理sparkstreaming模块、图计算GraphX等等；mapreduce只提供了map和reduce两种操作，流计算以及其他模块的支持比较缺乏。 
```

##### 4、框架和生态

```tex
spark框架和生态更为复杂，首先有RDD、血缘lineage、执行时的有向无环图DAG、stage划分等等，很多时候spark作业都需要根据不同业务场景的需要进行调优已达到性能要求；mapreduce框架及其生态相对较为简单，对性能的要求也相对较弱，但是运行较为稳定，适合长期后台运行。
```

##### 5、运行环境

```tex
MR运行在YARN上;
spark
(1) local：本地运行
(2) standalone：使用Spark自带的资源管理框架，运行spark的应用
(3) yarn：将spark应用类似mr一样，提交到yarn上运行
(4) mesos：类似yarn的一种资源管理框架

 总结，spark生态更为丰富，功能更为强大、性能更佳，适用范围更广；mapreduce更简单、稳定性好、适合离线海量数据挖掘计算。

```

##### 6： hive切换计算引擎

```tex
SET hive.execution.engine = {engine}; spark或者mr
```

##### 7： 弹性分布数据集RDD

```tex
-- 简单理解：
RDD：Resilient Distributed Dataset 弹性分布式数据集，是Spark中的基本抽象。
RDD表示可以并行操作的元素的不变分区集合。
RDD提供了许多基本的函数（map、filter、reduce等）供我们进行数据处理。

你将RDD理解为一个大的集合，将所有数据都加载到内存中，方便进行多次重用。
1: 第一，它是分布式的，可以分布在多台机器上，进行计算。
2: 第二，它是弹性的，在计算处理过程中，机器的内存不够时，它会和硬盘进行数据交换，某种程度上会减低性能，但是可以确保计算得以继续进行。

RDD(Resilient Distributed Dataset)是Spark的最基本抽象，是对分布式内存的抽象使用，实现了以操作本地集合的方式来操作分布式数据集的抽象实现。RDD是Spark最核心的东西，它表示已被分区，不可变的并能够被并行操作的数据集合，不同的数据集格式对应不同的RDD实现。

RDD必须是可序列化的。RDD可以cache到内存中，每次对RDD数据集的操作之后的结果，都可以存放到内存中，下一个操作可以直接从内存中输入，省去了MapReduce大量的磁盘IO操作。这对于迭代运算比较常见的机器学习算法, 交互式数据挖掘来说，效率提升比较大。
```

##### 7.1： RDD的组成

```tex
通常来说，每个RDD有5个主要的属性组成：
1: 分区列表
    RDD是由多个分区组成的，分区是逻辑上的概念。RDD的计算是以分区为单位进行的。
2: 用于计算每个分区的函数
    作用于每个分区数据的计算函数。
3: 对其他RDD的依赖关系列表
    RDD中保存了对于父RDD的依赖，根据依赖关系组成了Spark的DAG（有向无环图），实现了spark巧妙、容错的编程模型
4: 针对键值型RDD的分区器
    分区器针对键值型RDD而言的，将key传入分区器获取唯一的分区id。在shuffle中，分区器有很重要的体现。
5: 对每个分区进行计算的首选位置列表
    根据数据本地性的特性，获取计算的首选位置列表，尽可能的把计算分配到靠近数据的位置，减少数据的网络传输。

```

##### 7.2: RDD特性

```tex
RDD是分布式只读且已分区集合对象。这些集合是弹性的，如果数据集一部分丢失，则可以对它们进行重建。具有自动容错、位置感知调度和可伸缩性

1: 数据存储结构不可变
2: 支持跨集群的分布式数据操作
3: 可对数据记录按key进行分区
4: 提供了粗粒度的转换操作
5: 数据存储在内存中，保证了低延迟性
```

##### 7.3: RDD编程接口

```tex
对于RDD，有两种类型的动作，一种是Transformation，一种是Action。它们本质区别是：

Transformation返回值还是一个RDD。它使用了链式调用的设计模式，对一个RDD进行计算后，变换成另外一个RDD，然后这个RDD又可以进行另外一次转换。这个过程是分布式的
Action返回值不是一个RDD。它要么是一个Scala的普通集合，要么是一个值，要么是空，最终或返回到Driver程序，或把RDD写入到文件系统中
```

##### 7.4: RDD依赖关系

```tex
不同的操作依据其特性，可能会产生不同的依赖，RDD之间的依赖关系有以下两种：

7.3.1: 窄依赖(Narrow Dependencies): 父RDD的每个分区只被一个子RDD分区使用。
7.3.2: 宽依赖(Wide Dependencies): 父RDD的每个分区都有可能被多个子RDD分区使用
    
其实就是父RDD的一个分区会被传到几个子RDD分区的区别。如果被传到一个子RDD分区，就可以不需要移动数据（移动计算）；如果被传到多个子RDD分区，就需要进行数据的传输。

一些常见的宽窄依赖
窄依赖：map、filter、union、mapPartitions、join(当分区器是HashPartitioner)
宽依赖：sortByKey、join(分区器不是HashPartitioner时)
```

