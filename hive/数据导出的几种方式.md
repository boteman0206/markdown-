##### 1： Insert导出

```sql
-- 1．将查询的结果导出到本地
hive (default)> insert overwrite local directory '/opt/module/datas/export/student' select * from student;

-- 2．将查询的结果格式化导出到本地
hive(default)>insert overwrite local directory '/opt/module/datas/export/student1' ROW FORMAT DELIMITED FIELDS TERMINATED BY '\t'  select * from student;

-- 3．将查询的结果导出到HDFS上(没有local)
hive (default)> insert overwrite directory '/user/atguigu/student2'
             ROW FORMAT DELIMITED FIELDS TERMINATED BY '\t' 
             select * from student;
```

##### 2: Hadoop命令导出到本地

```sql
hive (default)> dfs -get /user/hive/warehouse/student/month=201709/000000_0
/opt/module/datas/export/student3.txt;
```

##### 3: **Hive Shell 命令导出**

```sql
基本语法：（hive -f/-e 执行语句或者脚本 > file）
[atguigu@hadoop102 hive]$ bin/hive -e 'select * from default.student;' >
 /opt/module/datas/export/student4.txt;
```

##### 4: **Export导出到HDFS上**

```sql
(defahiveult)> export table default.student to
 '/user/hive/warehouse/export/student';
```

##### **5:  Sqoop导出**

```sql

```

